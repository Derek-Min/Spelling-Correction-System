# Spelling Correction System (Business Domain Corpus)

This project implements a probabilistic spelling correction system using a domain-specific **business news corpus** instead of a traditional dictionary. The system detects non-word errors, real-word errors, semantic inconsistencies, and grammar issues while providing context-aware correction suggestions.

The project is built using **Streamlit**, **spaCy**, and a custom-built vocabulary extracted from 5,992 BUSINESS articles (over 500,000 words) from the *News Category Dataset (Kaggle)*.

---

## ğŸ“Œ Features

### âœ” Non-Word Error Detection  
Detects words not found in the business corpus (e.g., *â€œprouctâ€ â†’ "product"*).

### âœ” Real-Word Error Detection  
Checks confusion pairs (e.g., *"there" vs "their" vs "theyâ€™re"*).

### âœ” Semantic Checking  
Detects incorrect verb-object pairs (e.g., *â€œdrink riceâ€*, *â€œeat waterâ€*).

### âœ” Grammar Checking  
Handles subject-verb agreement (e.g., *â€œHe go to workâ€ â†’ â€œHe goes to workâ€*).

### âœ” Ranked Suggestions  
Uses:
- Levenshtein Edit Distance  
- Corpus word frequency  
to suggest the most likely replacement.

### âœ” Business Dictionary Panel  
Displays 4,000+ business-domain words extracted from the corpus.

### âœ” Clean UI  
JetBrains-style dark interface with animated wavy underlines for error highlights.

---

## ğŸ“ Project Structure

pelling-Correction-System/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ clean_business_corpus.txt
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## ğŸ§  How the System Works

### 1. **Corpus-Based Vocabulary**
Instead of a generic English dictionary, the system reads:


This file contains cleaned text from thousands of business news articles.  
Words are extracted and counted to form:

- A domain-specific dictionary  
- A frequency model (used for probabilistic spelling suggestions)

### 2. **Edit Distance Algorithm**
The system finds candidate words within edit distance â‰¤ 2 and ranks them by:

1. Lowest edit distance  
2. Highest frequency in the corpus  

### 3. **Real-Word Confusion Sets**
Handles mistakes where the word exists but is wrong in context:
- *there / their / theyâ€™re*
- *to / too / two*
- *form / from*

### 4. **Semantic Rules**
Basic verb-object rules ensure meaningful corrections:
- â€œeat waterâ€ â†’ incorrect  
- â€œdrink riceâ€ â†’ incorrect  

### 5. **Grammar Checking**
Uses spaCy POS tagging to detect subject-verb mismatches.

---

## ğŸš€ Running the Application

### 1. Install dependencies
Run:

### 2. Install spaCy English model (required)


### 3. Start the Streamlit app


### 4. Ensure the corpus file exists
Make sure `clean_business_corpus.txt` is in the same folder as `app.py`.

---

## ğŸ“š Dataset Information

The corpus used in this project is derived from:

**News Category Dataset (Kaggle)**  
Only the **BUSINESS** category was extracted (~5,992 articles).  

These were combined, cleaned, and saved into:


The final corpus contains **over 500,000 words**, meeting the assignment requirement of a minimum 100,000-word domain corpus.

---

## ğŸ§‘â€ğŸ« Academic Requirements (APU)

This project fulfills the following NLP assignment components:

### âœ” Candidate Techniques  
- Edit Distance  
- Bigram/Context Principles  
- Part-of-Speech tagging  
- Corpus-driven modeling  

### âœ” Design & Formulation  
- GUI-based spell-checking system  
- Domain-specific dictionary  
- Real-word and semantic error detection  

### âœ” Implementation  
- Clean and efficient Python code  
- Custom probabilistic model  
- Streamlit interface  

### âœ” Results  
- Screenshots in the report  
- Demonstration through working GUI  

---

## ğŸ™Œ Author
**Min Thant Wai**  
Asia Pacific University â€“ Natural Language Processing  
Spelling Correction System Project (2025)

